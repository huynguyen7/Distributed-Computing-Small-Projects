* GOOD EXPLANATION *
https://en.wikipedia.org/wiki/MapReduce
https://en.wikipedia.org/wiki/Apache_Spark (FRAMEWORK)

** MapReduce paradigm **
The input to a MapReduce style computation is a set of key-value pairs. The keys are similar to keys used in hash tables, and the functional programming approach requires that both the keys and values be immutable. When a user-specified map function, f(), is applied on a key-value pair, (kA,vA), it results in a (possibly empty) set of output key-value pairs, {(kA1,vA1), (kA2, vA2),...}. This map function can be applied in parallel on all key-value pairs in the input set, to obtain a set of intermediate key-value pairs that is the union of all the outputs.
The next operation performed in the MapReduce workflow is referred to as 'grouping', which groups together all intermediate key-value pairs with the same key. When a user-specified reduce function, g(), is applied on two or more grouped values associated with the same key k, it folds or reduces all those values to obtain a SINGLE output key-value pair for EACH key k, in the intermediate key-value set generated by the map function.

** Project explanations **
Ranking inter-connected websites based on existing ranks and link counts by using Apache Spark.

** Usage **
Run the command line:
$ mvn test
